from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
import pickle
import cv2
import numpy as np
import torch
import torchvision.models as models
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms
import io
import os
from typing import Optional
import base64

app = FastAPI(title="Dog Breed Predictor", description="Find out which dog breed you look like!")

# ì „ì—­ ë³€ìˆ˜ë“¤
loaded_model = None
class_names = None


def load_model_from_pkl(pkl_path: str):
    """pkl íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ - Custom unpickler ì‚¬ìš©"""
    print(f"ğŸ” Loading model from {pkl_path}")
    print(f"ğŸ” PyTorch version: {torch.__version__}")
    print(f"ğŸ” CUDA available: {torch.cuda.is_available()}")

    try:
        print("ğŸ“¥ Loading with custom CPU unpickler...")
        import pickle
        import io

        class CPUUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                if module == 'torch.storage' and name == '_load_from_bytes':
                    return lambda b: torch.load(io.BytesIO(b), map_location='cpu')
                else:
                    return super().find_class(module, name)

        with open(pkl_path, 'rb') as f:
            model_package = CPUUnpickler(f).load()

        print(f"âœ… Model loaded successfully!")
        return model_package

    except FileNotFoundError:
        print(f"âŒ Model file {pkl_path} not found")
        return None
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        return None


def rebuild_model_from_package(model_package: dict, use_cuda: bool = True):
    """íŒ¨í‚¤ì§€ì—ì„œ ëª¨ë¸ ì¬êµ¬ì„±"""
    if model_package is None:
        return None

    try:
        # VGG16 ëª¨ë¸ êµ¬ì¡° ì¬ìƒì„±
        model = models.vgg16(pretrained=True)

        # ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µì„ 133ê°œ í´ë˜ìŠ¤ë¡œ ë³€ê²½
        n_inputs = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(n_inputs, model_package['num_classes'])

        # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (CPU í™˜ê²½ ê³ ë ¤)
        state_dict = model_package['model_state_dict']

        # GPUì—ì„œ ì €ì¥ëœ ëª¨ë¸ì„ CPUì—ì„œ ë¡œë“œí•˜ëŠ” ê²½ìš° ì²˜ë¦¬
        if not torch.cuda.is_available() and use_cuda:
            # GPU í…ì„œë¥¼ CPUë¡œ ë³€í™˜
            cpu_state_dict = {}
            for key, value in state_dict.items():
                if torch.is_tensor(value):
                    cpu_state_dict[key] = value.cpu()
                else:
                    cpu_state_dict[key] = value
            state_dict = cpu_state_dict
            use_cuda = False  # CUDA ì‚¬ìš© ë¶ˆê°€í•˜ë¯€ë¡œ Falseë¡œ ì„¤ì •

        model.load_state_dict(state_dict)

        # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        model.eval()

        # GPU ì‚¬ìš© ì„¤ì •
        if use_cuda and torch.cuda.is_available():
            model = model.cuda()
            print("âœ… Model loaded on GPU")
        else:
            print("âœ… Model loaded on CPU")

        return model
    except Exception as e:
        print(f"âŒ Error rebuilding model: {e}")
        return None


def face_detector(image_bytes: bytes) -> bool:
    """ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ"""
    try:
        # bytesë¥¼ numpy arrayë¡œ ë³€í™˜
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            return False

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # OpenCVì˜ ê¸°ë³¸ ì–¼êµ´ ê²€ì¶œê¸° ì‚¬ìš© (haarcascade íŒŒì¼ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

        return len(faces) > 0
    except Exception as e:
        print(f"âŒ Face detection error: {e}")
        return False


def predict_breed_from_image(image_bytes: bytes) -> Optional[str]:
    """ì´ë¯¸ì§€ì—ì„œ ê°œ í’ˆì¢… ì˜ˆì¸¡"""
    if loaded_model is None or class_names is None:
        return None

    try:
        # bytesë¥¼ PIL Imageë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (VGG16ìš©)
        transformations = transforms.Compose([
            transforms.Resize(size=224),
            transforms.CenterCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        image_tensor = transformations(image)[:3, :, :].unsqueeze(0)

        # GPUë¡œ ì´ë™ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
        use_cuda = torch.cuda.is_available()
        if use_cuda:
            try:
                image_tensor = image_tensor.cuda()
            except Exception as e:
                print(f"âš ï¸ Failed to move tensor to GPU: {e}. Using CPU instead.")
                use_cuda = False

        # ì˜ˆì¸¡ ìˆ˜í–‰
        with torch.no_grad():
            output = loaded_model(image_tensor)
            _, pred_tensor = torch.max(output, 1)
            pred = pred_tensor.cpu().numpy()[0] if use_cuda else pred_tensor.numpy()[0]

        return class_names[pred]
    except Exception as e:
        print(f"âŒ Prediction error: {e}")
        return None


# ì•± ì‹œì‘ì‹œ ëª¨ë¸ ë¡œë“œ
@app.on_event("startup")
async def startup_event():
    global loaded_model, class_names

    print("ğŸš€ Starting up FastAPI Dog Breed Predictor...")

    # ëª¨ë¸ ë¡œë“œ
    model_package = load_model_from_pkl('dog_classifier.pkl')
    if model_package:
        # CPU í™˜ê²½ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ ì¬êµ¬ì„±
        use_cuda = torch.cuda.is_available()
        loaded_model = rebuild_model_from_package(model_package, use_cuda=use_cuda)
        class_names = model_package['class_names']
        print(f"ğŸ“ Loaded {len(class_names)} class names")

        if not use_cuda:
            print("âš ï¸ CUDA not available. Running on CPU mode.")
    else:
        print("âš ï¸ Failed to load model. Some features may not work.")


@app.get("/", response_class=HTMLResponse)
async def main():
    """ë©”ì¸ í˜ì´ì§€"""
    html_content = """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ë‚˜ì™€ ë‹®ì€ ë™ë¬¼ì€?</title>
        <style>
            body {
                font-family: 'Arial', sans-serif;
                background-color: #FFF4F2;
                text-align: center;
                padding: 20px;
            }
            h1 {
                color: #FF4C8B;
                font-size: 2.5em;
            }
            .subheading {
                background-color: #FFB5A7;
                color: white;
                padding: 10px;
                margin-bottom: 30px;
                font-size: 1.2em;
                border-radius: 8px;
            }
            .upload-form {
                background-color: #FFE5DC;
                border: 3px dashed #FFB5A7;
                padding: 30px;
                border-radius: 15px;
                display: inline-block;
                cursor: pointer;
                transition: all 0.3s ease;
            }
            .upload-form:hover {
                border-color: #FF6F91;
                background-color: #FFD5CC;
            }
            input[type="file"] {
                display: none;
            }
            .upload-btn {
                background-color: #FF6F91;
                color: white;
                border: none;
                padding: 15px 30px;
                font-size: 1.1em;
                border-radius: 10px;
                cursor: pointer;
                margin-top: 20px;
                transition: background-color 0.3s;
            }
            .upload-btn:hover {
                background-color: #FF4C8B;
            }
            .upload-btn:disabled {
                background-color: #ccc;
                cursor: not-allowed;
            }
            .preview-img {
                max-width: 300px;
                max-height: 300px;
                border-radius: 15px;
                margin: 20px auto;
                display: block;
                box-shadow: 0 4px 8px rgba(0,0,0,0.2);
            }
            .result {
                margin-top: 30px;
                padding: 20px;
                background-color: white;
                border-radius: 15px;
                box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                display: inline-block;
            }
            .result h2 {
                color: #FF4C8B;
                font-size: 2em;
                margin-bottom: 20px;
            }
            .result-animal {
                font-size: 2.5em;
                color: #FF6F91;
                font-weight: bold;
                margin: 20px 0;
            }
            .loading {
                color: #FF6F91;
                font-size: 1.2em;
                margin: 20px 0;
            }
            .error {
                color: #ff4444;
                background-color: #ffe6e6;
                border: 2px solid #ff4444;
                padding: 15px;
                border-radius: 10px;
                margin: 20px auto;
                display: inline-block;
            }
            .survey {
                margin-top: 50px;
                background-color: #fff;
                border-radius: 15px;
                padding: 20px;
                display: inline-block;
                box-shadow: 0 0 10px rgba(0,0,0,0.1);
            }
            .survey a {
                display: inline-block;
                margin-top: 10px;
                background-color: #FF4C8B;
                color: white;
                padding: 10px 20px;
                border-radius: 8px;
                text-decoration: none;
                font-weight: bold;
            }
            .survey a:hover {
                background-color: #FF6F91;
            }
            .status-indicator {
                position: fixed;
                top: 20px;
                right: 20px;
                padding: 10px 15px;
                border-radius: 10px;
                font-size: 0.9em;
                font-weight: bold;
            }
            .status-ok {
                background: rgba(76, 175, 80, 0.9);
                color: white;
            }
            .status-error {
                background: rgba(244, 67, 54, 0.9);
                color: white;
            }
            @media (max-width: 600px) {
                .preview-img {
                    width: 90%;
                }
                .upload-form {
                    width: 90%;
                }
            }
        </style>
    </head>
    <body>
        <div id="statusIndicator" class="status-indicator">ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘...</div>
        
        <h1>ë‚˜ì™€ ë‹®ì€ ë™ë¬¼ì€? ğŸ•</h1>
        <div class="subheading">ë‚˜ëŠ” ì–´ë–¤ ë™ë¬¼ê³¼ ë‹®ì•˜ì„ê¹Œ? ì‚¬ì§„ì„ ì—…ë¡œë“œ í•˜ë©´, ë‚˜ì™€ ë‹®ì€ ë™ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</div>
        
        <div class="upload-form" onclick="document.getElementById('fileInput').click()">
            <p>ğŸ“· ì—¬ê¸°ë¥¼ í´ë¦­í•´ì„œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”</p>
            <p style="font-size: 0.9em; color: #666;">JPG, PNG íŒŒì¼ ì§€ì›</p>
            <input type="file" id="fileInput" accept="image/*" onchange="previewImage()">
        </div>

        <div id="preview"></div>

        <button class="upload-btn" id="analyzeBtn" onclick="analyzeImage()" disabled>
            ğŸ” ë™ë¬¼ ì°¾ê¸°!
        </button>

        <div id="result"></div>

        <div class="survey">
            <p>ì„¤ë¬¸ì¡°ì‚¬ì— ì°¸ì—¬í•´ì£¼ì‹œë©´<br>ì¶”ì²¨ì„ í†µí•´ ì†Œì •ì˜ ê¸°í”„í‹°ì½˜ì„ ë“œë¦½ë‹ˆë‹¤.<br>ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š</p>
            <a href="https://docs.google.com/forms/d/e/1FAIpQLSfM0CURwgynFKiXDLbLxwsHoBIdyhgKRsPZrGSlI-_ScEU1NA/viewform" target="_blank">ì„¤ë¬¸ì¡°ì‚¬ ë°”ë¡œê°€ê¸°</a>
        </div>

        <script>
            let selectedFile = null;

            // í˜ì´ì§€ ë¡œë“œ ì‹œ ëª¨ë¸ ìƒíƒœ í™•ì¸
            window.onload = function() {
                checkModelStatus();
            };

            async function checkModelStatus() {
                const statusIndicator = document.getElementById('statusIndicator');
                try {
                    const response = await fetch('/health');
                    const status = await response.json();
                    
                    if (status.model_status === 'loaded') {
                        statusIndicator.textContent = 'âœ… AI ì¤€ë¹„ì™„ë£Œ';
                        statusIndicator.className = 'status-indicator status-ok';
                    } else {
                        statusIndicator.textContent = 'âŒ AI ë¡œë”© ì¤‘';
                        statusIndicator.className = 'status-indicator status-error';
                    }
                } catch (error) {
                    statusIndicator.textContent = 'âŒ ì„œë²„ ì˜¤ë¥˜';
                    statusIndicator.className = 'status-indicator status-error';
                }
            }

            function previewImage() {
                const fileInput = document.getElementById('fileInput');
                const preview = document.getElementById('preview');
                const analyzeBtn = document.getElementById('analyzeBtn');

                if (fileInput.files && fileInput.files[0]) {
                    selectedFile = fileInput.files[0];
                    const reader = new FileReader();

                    reader.onload = function(e) {
                        preview.innerHTML = '<img src="' + e.target.result + '" class="preview-img" alt="ë¯¸ë¦¬ë³´ê¸°">';
                        analyzeBtn.disabled = false;
                    }

                    reader.readAsDataURL(fileInput.files[0]);
                }
            }

            async function analyzeImage() {
                if (!selectedFile) {
                    alert('ë¨¼ì € ì‚¬ì§„ì„ ì„ íƒí•´ì£¼ì„¸ìš”!');
                    return;
                }

                const resultDiv = document.getElementById('result');
                const analyzeBtn = document.getElementById('analyzeBtn');

                // ë¡œë”© ìƒíƒœ
                resultDiv.innerHTML = '<div class="loading">ğŸ” ì‚¬ì§„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!</div>';
                analyzeBtn.disabled = true;

                const formData = new FormData();
                formData.append('file', selectedFile);

                try {
                    const response = await fetch('/predict', {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();

                    if (response.ok) {
                        if (result.success) {
                            resultDiv.innerHTML = `
                                <div class="result">
                                    <h2>ğŸ‰ ë¶„ì„ ì™„ë£Œ!</h2>
                                    <p>ë‹¹ì‹ ê³¼ ë‹®ì€ ë™ë¬¼ì€:</p>
                                    <div class="result-animal">${result.breed}</div>
                                    <p style="color: #666; margin-top: 20px;">
                                        ì´ í’ˆì¢…ì´ ë‹¹ì‹ ì˜ íŠ¹ì§•ê³¼ ê°€ì¥ ì˜ ì–´ìš¸ë ¤ìš”! ğŸ¾
                                    </p>
                                </div>
                            `;
                        } else {
                            resultDiv.innerHTML = `
                                <div class="error">
                                    <h3>ğŸ˜… ${result.message}</h3>
                                    <p>ì–¼êµ´ì´ ì„ ëª…í•˜ê²Œ ë‚˜ì˜¨ ì‚¬ì§„ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!</p>
                                </div>
                            `;
                        }
                    } else {
                        throw new Error(result.detail || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
                    }
                } catch (error) {
                    resultDiv.innerHTML = `
                        <div class="error">
                            <h3>âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤</h3>
                            <p>${error.message}</p>
                            <p>ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.</p>
                        </div>
                    `;
                } finally {
                    analyzeBtn.disabled = false;
                }
            }
        </script>
    </body>
    </html>
    
    """
    return HTMLResponse(content=html_content)


@app.post("/predict")
async def predict_dog_breed(file: UploadFile = File(...)):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ í›„ ê°œ í’ˆì¢… ì˜ˆì¸¡"""

    # íŒŒì¼ í˜•ì‹ í™•ì¸
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Please upload an image file")

    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await file.read()

        # ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if loaded_model is None:
            raise HTTPException(status_code=500, detail="Model not loaded. Please check server logs.")

        # ì–¼êµ´ ê²€ì¶œ
        if not face_detector(image_bytes):
            return JSONResponse(content={
                "success": False,
                "message": "No human face detected in the image! ğŸ‘¤âŒ"
            })

        # ê°œ í’ˆì¢… ì˜ˆì¸¡
        predicted_breed = predict_breed_from_image(image_bytes)

        if predicted_breed is None:
            raise HTTPException(status_code=500, detail="Failed to predict breed")

        return JSONResponse(content={
            "success": True,
            "breed": predicted_breed,
            "message": f"You look like a {predicted_breed}! ğŸ•"
        })

    except Exception as e:
        print(f"âŒ Error in prediction: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    model_status = "loaded" if loaded_model is not None else "not loaded"
    return {
        "status": "healthy",
        "model_status": model_status,
        "classes_loaded": len(class_names) if class_names else 0
    }


if __name__ == "__main__":
    import uvicorn

    print("ğŸš€ Starting Dog Breed Predictor Server...")
    print("ğŸ“ Server will be available at: http://localhost:8000")
    print("ğŸ“‹ API docs will be available at: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)