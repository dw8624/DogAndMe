import pickle
import matplotlib.pyplot as plt
import cv2
import numpy as np
import torch
import torchvision.models as models
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms


def load_model_from_pkl(pkl_path):
    """pkl íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
    with open(pkl_path, 'rb') as f:
        model_package = pickle.load(f)

    print("ğŸ“¦ Model package contents:")
    for key, value in model_package.items():
        if key != 'model_state_dict':  # state_dictëŠ” ë„ˆë¬´ í¬ë‹ˆê¹Œ ì œì™¸
            print(f"  {key}: {value}")

    return model_package


# ëª¨ë¸ íŒ¨í‚¤ì§€ ë¡œë“œ
model_package = load_model_from_pkl('dog_classifier.pkl')


def rebuild_model_from_package(model_package, use_cuda=True):
    """íŒ¨í‚¤ì§€ì—ì„œ ëª¨ë¸ ì¬êµ¬ì„±"""

    # VGG16 ëª¨ë¸ êµ¬ì¡° ì¬ìƒì„±
    model = models.vgg16(pretrained=True)

    # ë§ˆì§€ë§‰ ë¶„ë¥˜ì¸µì„ 133ê°œ í´ë˜ìŠ¤ë¡œ ë³€ê²½
    n_inputs = model.classifier[6].in_features
    model.classifier[6] = nn.Linear(n_inputs, model_package['num_classes'])

    # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(model_package['model_state_dict'])

    # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    model.eval()

    # GPU ì‚¬ìš© ì„¤ì •
    if use_cuda and torch.cuda.is_available():
        model = model.cuda()
        print("âœ… Model loaded on GPU")
    else:
        print("âœ… Model loaded on CPU")

    return model


# ëª¨ë¸ ì¬êµ¬ì„±
loaded_model = rebuild_model_from_package(model_package, use_cuda=torch.cuda.is_available())

# pklì—ì„œ ë¡œë“œí•œ í´ë˜ìŠ¤ ì´ë¦„ë“¤ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •
class_names = model_package['class_names']
print(f"ğŸ“ Loaded {len(class_names)} class names")
print(f"First 5 classes: {class_names[:5]}")


def predict_breed_from_loaded_model(img_path, model, class_names, use_cuda=True):
    """ë¡œë“œëœ ëª¨ë¸ë¡œ í’ˆì¢… ì˜ˆì¸¡"""

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (VGG16ìš©)
    def image_to_tensor(img_path):
        img = Image.open(img_path).convert('RGB')
        transformations = transforms.Compose([
            transforms.Resize(size=224),
            transforms.CenterCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])
        return transformations(img)[:3, :, :].unsqueeze(0)

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image_tensor = image_to_tensor(img_path)

    # GPUë¡œ ì´ë™
    if use_cuda and torch.cuda.is_available():
        image_tensor = image_tensor.cuda()

    # ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´
        output = model(image_tensor)
        _, pred_tensor = torch.max(output, 1)
        pred = pred_tensor.cpu().numpy()[0] if use_cuda else pred_tensor.numpy()[0]

    return class_names[pred]

def load_convert_image_to_tensor(img_path):
    image = Image.open(img_path).convert('RGB')
    # resize to (244, 244) because VGG16 accept this shape
    in_transform = transforms.Compose([
                        transforms.Resize(size=(244, 244)),
                        transforms.ToTensor()]) # normalization .

    # discard the transparent, alpha channel (that's the :3) and add the batch dimension
    image = in_transform(image)[:3,:,:].unsqueeze(0)
    return image

def VGG16_predict(img_path):
    image_tensor = load_convert_image_to_tensor(img_path)
    VGG16 = models.vgg16(pretrained=True)
    use_cuda = torch.cuda.is_available()

    if use_cuda:
        VGG16 = VGG16.cuda()

    # move model inputs to cuda, if GPU available
    if use_cuda:
        image_tensor = image_tensor.cuda()

    # get sample outputs
    output = VGG16(image_tensor)
    # convert output probabilities to predicted class
    _, preds_tensor = torch.max(output, 1)
    pred = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())

    return int(pred)  # predicted class index

def dog_detector(img_path):
    prediction = VGG16_predict(img_path)
    return ((prediction >= 151) & (prediction <= 268))  # true/false

def face_detector(img_path):
    img = cv2.imread(img_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')
    faces = face_cascade.detectMultiScale(gray)
    return len(faces) > 0


def run_app_with_loaded_model(img_path, model, class_names):
    """ë¡œë“œëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” run_app"""

    # ì´ë¯¸ì§€ í‘œì‹œ í•¨ìˆ˜
    def display_image(img_path, title="Title"):
        image = Image.open(img_path)
        plt.figure(figsize=(8, 6))
        plt.title(title, fontsize=14, fontweight='bold')
        plt.imshow(image)
        plt.axis('off')
        plt.show()

    print("ğŸ” Analyzing image...")

    # ê°•ì•„ì§€ ê²€ì¶œ
    if dog_detector(img_path):
        print("ğŸ• Hello Doggie!")
        predicted_breed = predict_breed_from_loaded_model(img_path, model, class_names)
        display_image(img_path, title=f"Predicted Breed: {predicted_breed}")
        print(f"ğŸ¯ Your breed is most likely: {predicted_breed.upper()}")

    # ì‚¬ëŒ ì–¼êµ´ ê²€ì¶œ
    elif face_detector(img_path):
        print("ğŸ‘¨ Hello Human!")
        predicted_breed = predict_breed_from_loaded_model(img_path, model, class_names)
        display_image(img_path, title=f"You look like: {predicted_breed}")
        print(f"ğŸ­ You look like a: {predicted_breed.upper()}")

    else:
        print("âŒ Oh, we're sorry! We couldn't detect any dog or human face in the image.")
        display_image(img_path, title="No detection")
        print("ğŸ”„ Try another image!")

    print("=" * 50)

# 1. ëª¨ë¸ ë¡œë“œ
print("ğŸ“¥ Loading model from pkl file...")
model_package = load_model_from_pkl('dog_classifier.pkl')

# 2. ëª¨ë¸ ì¬êµ¬ì„±
print("ğŸ”§ Rebuilding model...")
loaded_model = rebuild_model_from_package(model_package)

# 3. í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
class_names = model_package['class_names']

# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print("ğŸ¯ Testing loaded model...")

run_app_with_loaded_model("test11.jpg", loaded_model, class_names)